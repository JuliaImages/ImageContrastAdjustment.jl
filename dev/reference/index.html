<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Function References · Documentation</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Documentation</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">ImageContrastAdjustment.jl Documentation</a></li><li class="is-active"><a class="tocitem" href>Function References</a><ul class="internal"><li><a class="tocitem" href="#General-function-1"><span>General function</span></a></li><li><a class="tocitem" href="#Algorithms-1"><span>Algorithms</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Function References</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Function References</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaImages/ImageContrastAdjustment.jl/blob/master/docs/src/reference.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="function_reference-1"><a class="docs-heading-anchor" href="#function_reference-1">Function References</a><a class="docs-heading-anchor-permalink" href="#function_reference-1" title="Permalink"></a></h1><ul><li><a href="#function_reference-1">Function References</a></li><ul><li><a href="#General-function-1">General function</a></li><li><a href="#Algorithms-1">Algorithms</a></li><ul><li><a href="#AdaptiveEqualization-1">AdaptiveEqualization</a></li><li><a href="#ContrastStretching-1">ContrastStretching</a></li><li><a href="#Equalization-1">Equalization</a></li><li><a href="#LinearStretching-1">LinearStretching</a></li><li><a href="#Matching-1">Matching</a></li><li><a href="#MidwayEqualization-1">MidwayEqualization</a></li></ul></ul></ul><h2 id="General-function-1"><a class="docs-heading-anchor" href="#General-function-1">General function</a><a class="docs-heading-anchor-permalink" href="#General-function-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ImageContrastAdjustment.HistogramAdjustmentAPI.adjust_histogram" href="#ImageContrastAdjustment.HistogramAdjustmentAPI.adjust_histogram"><code>ImageContrastAdjustment.HistogramAdjustmentAPI.adjust_histogram</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">adjust_histogram([T::Type,] img, f::AbstractHistogramAdjustmentAlgorithm, args...; kwargs...)</code></pre><p>Adjust histogram of <code>img</code> using algorithm <code>f</code>.</p><p><strong>Output</strong></p><p>The return image <code>img_adjusted</code> is an <code>Array{T}</code>.</p><p>If <code>T</code> is not specified, then it&#39;s inferred.</p><p><strong>Examples</strong></p><p>Just simply pass the input image and algorithm to <code>adjust_histogram</code></p><pre><code class="language-julia">img_adjusted = adjust_histogram(img, f)</code></pre><p>This reads as &quot;<code>adjust_histogram</code> of image <code>img</code> using algorithm <code>f</code>&quot;.</p><p>You can also explicitly specify the return type:</p><pre><code class="language-julia">img_adjusted_float32 = adjust_histogram(Gray{Float32}, img, f)</code></pre><p>See also <a href="#ImageContrastAdjustment.HistogramAdjustmentAPI.adjust_histogram!"><code>adjust_histogram!</code></a> for in-place histogram adjustment.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaImages/ImageContrastAdjustment.jl/blob/5642b3a02e4a24c7f2b528f64870e56f7ab3393e/src/HistogramAdjustmentAPI/histogram_adjustment.jl#L148-L175">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageContrastAdjustment.HistogramAdjustmentAPI.adjust_histogram!" href="#ImageContrastAdjustment.HistogramAdjustmentAPI.adjust_histogram!"><code>ImageContrastAdjustment.HistogramAdjustmentAPI.adjust_histogram!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">adjust_histogram!([out,] img, f::AbstractHistogramAdjustmentAlgorithm, args...; kwargs...)</code></pre><p>Adjust histogram of <code>img</code> using algorithm <code>f</code>.</p><p><strong>Output</strong></p><p>If <code>out</code> is specified, it will be changed in place. Otherwise <code>img</code> will be changed in place.</p><p><strong>Examples</strong></p><p>Just simply pass an algorithm to <code>adjust_histogram!</code>:</p><pre><code class="language-julia">img_adjusted = similar(img)
adjust_histogram!(img_adjusted, img, f)</code></pre><p>For cases you just want to change <code>img</code> in place, you don&#39;t necessarily need to manually allocate <code>img_adjusted</code>; just use the convenient method:</p><pre><code class="language-julia">adjust_histogram!(img, f)</code></pre><p>See also: <a href="#ImageContrastAdjustment.HistogramAdjustmentAPI.adjust_histogram"><code>adjust_histogram</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaImages/ImageContrastAdjustment.jl/blob/5642b3a02e4a24c7f2b528f64870e56f7ab3393e/src/HistogramAdjustmentAPI/histogram_adjustment.jl#L119-L145">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageContrastAdjustment.build_histogram" href="#ImageContrastAdjustment.build_histogram"><code>ImageContrastAdjustment.build_histogram</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">edges, count = build_histogram(img)            # For 8-bit images only
edges, count = build_histogram(img, nbins)
edges, count = build_histogram(img, nbins; minval, maxval)
edges, count = build_histogram(img, edges)</code></pre><p>Generates a histogram for the image over <code>nbins</code> spread between <code>[minval, maxval]</code>. Color images are automatically converted to grayscale.</p><p><strong>Output</strong></p><p>Returns <code>edges</code> which is a <code>AbstractRange</code> type that specifies how the  interval <code>[minval, maxval]</code> is divided into bins, and an array <code>count</code> which records the concomitant bin frequencies. In particular, <code>count</code> has the following properties:</p><ul><li><code>count[0]</code> is the number satisfying <code>x &lt; edges[1]</code></li><li><code>count[i]</code> is the number of values <code>x</code> that satisfy <code>edges[i] &lt;= x &lt; edges[i+1]</code></li><li><code>count[end]</code> is the number satisfying <code>x &gt;= edges[end]</code>.</li><li><code>length(count) == length(edges)+1</code>.</li></ul><p><strong>Details</strong></p><p>One can consider a histogram as a piecewise-constant model of a probability density function <span>$f$</span> [1]. Suppose that <span>$f$</span> has support on some interval <span>$I = [a,b]$</span>.  Let <span>$m$</span> be an integer and <span>$a = a_1 &lt; a_2 &lt; \ldots &lt; a_m &lt; a_{m+1} = b$</span> a sequence of real numbers. Construct a sequence of intervals</p><div>\[I_1 = [a_1,a_2], I_2 = (a_2, a_3], \ldots, I_{m} = (a_m,a_{m+1}]\]</div><p>which partition <span>$I$</span> into subsets <span>$I_j$</span> <span>$(j = 1, \ldots, m)$</span> on which <span>$f$</span> is constant. These subsets satisfy <span>$I_i \cap I_j = \emptyset, \forall i \neq j$</span>, and are commonly referred to as <em>bins</em>. Together they encompass the entire range of data values such that <span>$\sum_j |I_j | = | I |$</span>. Each bin has width <span>$w_j = |I_j| = a_{j+1} - a_j$</span> and height <span>$h_j$</span> which is the constant probability density over the region of the bin. Integrating the constant probability density over the width of the bin <span>$w_j$</span> yields a probability mass of <span>$\pi_j = h_j w_j$</span> for the bin.</p><p>For a sample <span>$x_1, x_2, \ldots, x_N$</span>, let</p><div>\[n_j = \sum_{n = 1}^{N}\mathbf{1}_{(I_j)}(x_n),
\quad \text{where} \quad
\mathbf{1}_{(I_j)}(x) =
\begin{cases}
 1 &amp; \text{if} \; x \in I_j,\\
 0 &amp; \text{otherwise},
\end{cases},\]</div><p>represent the number of samples falling into the interval <span>$I_j$</span>. An estimate for the probability mass of the <span>$j$</span>th bin is given by the relative frequency <span>$\hat{\pi} = \frac{n_j}{N}$</span>, and the histogram estimator of the probability density function is defined as</p><div>\[\begin{aligned}
\hat{f}_n(x)  &amp; = \sum_{j = 1}^{m}\frac{n_j}{Nw_j} \mathbf{1}_{(I_j)}(x) \\
&amp; = \sum_{j = 1}^{m}\frac{\hat{\pi}_j}{w_j} \mathbf{1}_{(I_j)}(x) \\
&amp; = \sum_{j = 1}^{m}\hat{h}_j \mathbf{1}_{(I_j)}(x).
\end{aligned}\]</div><p>The function <span>$\hat{f}_n(x)$</span> is a genuine density estimator because <span>$\hat{f}_n(x)  \ge 0$</span> and</p><div>\[\begin{aligned}
\int_{-\infty}^{\infty}\hat{f}_n(x) \operatorname{d}x &amp; = \sum_{j=1}^{m} \frac{n_j}{Nw_j} w_j \\
&amp; = 1.
\end{aligned}\]</div><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>nbins</code></strong></p><p>You can specify the number of discrete bins for the histogram. When specifying the number of bins consider the maximum number of graylevels that your image type supports. For example, with an image of type <code>N0f8</code> there is a maximum of 256 possible graylevels. Hence, if you request more than 256 bins for that type of image you should expect to obtain zero counts for numerous bins.</p><p><strong>Choices for <code>minval</code></strong></p><p>You have the option to specify the lower bound of the interval over which the histogram will be computed.  If <code>minval</code> is not specified then the minimum value present in the image is taken as the lower bound.</p><p><strong>Choices for <code>maxval</code></strong></p><p>You have the option to specify the upper bound of the interval over which the histogram will be computed.  If <code>maxval</code> is not specified then the maximum value present in the image is taken as the upper bound.</p><p><strong>Choices for <code>edges</code></strong></p><p>If you do not designate the number of bins, nor the lower or upper bound of the interval, then you have the option to directly stipulate how the intervals will be divided by specifying a <code>AbstractRange</code> type.</p><p><strong>Example</strong></p><p>Compute the histogram of a grayscale image.</p><pre><code class="language-julia">
using TestImages, FileIO, ImageView

img =  testimage(&quot;mandril_gray&quot;);
edges, counts  = build_histogram(img, 256, minval = 0, maxval = 1)</code></pre><p>Given a color image, compute the histogram of the red channel.</p><pre><code class="language-julia">img = testimage(&quot;mandrill&quot;)
r = red.(img)
edges, counts  = build_histogram(r, 256, minval = 0, maxval = 1)</code></pre><p><strong>References</strong></p><p>[1] E. Herrholz, &quot;Parsimonious Histograms,&quot; Ph.D. dissertation, Inst. of Math. and Comp. Sci., University of Greifswald, Greifswald, Germany, 2011.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaImages/ImageContrastAdjustment.jl/blob/5642b3a02e4a24c7f2b528f64870e56f7ab3393e/src/build_histogram.jl#L27-L148">source</a></section></article><h2 id="Algorithms-1"><a class="docs-heading-anchor" href="#Algorithms-1">Algorithms</a><a class="docs-heading-anchor-permalink" href="#Algorithms-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ImageContrastAdjustment.HistogramAdjustmentAPI.AbstractHistogramAdjustmentAlgorithm" href="#ImageContrastAdjustment.HistogramAdjustmentAPI.AbstractHistogramAdjustmentAlgorithm"><code>ImageContrastAdjustment.HistogramAdjustmentAPI.AbstractHistogramAdjustmentAlgorithm</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">AbstractHistogramAdjustmentAlgorithm &lt;: AbstractImageFilter</code></pre><p>The root type for <code>ImageContrastAdjustment</code> package.</p><p>Any concrete histogram adjustment algorithm shall subtype it to support <a href="#ImageContrastAdjustment.HistogramAdjustmentAPI.adjust_histogram"><code>adjust_histogram</code></a> and <a href="#ImageContrastAdjustment.HistogramAdjustmentAPI.adjust_histogram!"><code>adjust_histogram!</code></a> APIs.</p><p><strong>Examples</strong></p><p>All histogram adjustment algorithms in ImageContrastAdjustment are called in the following pattern:</p><pre><code class="language-julia"># first generate an algorithm instance
f = LinearStretching()

# then pass the algorithm to `adjust_histogram`
img_adjusted = adjust_histogram(img, f)

# or use in-place version `adjust_histogram!`
img_adjusted = similar(img)
adjust_histogram!(img_adjusted, img, f)</code></pre><p>Some algorithms also receive additional information as an argument, e.g., <code>nbins</code> of <code>Equalization</code>.</p><pre><code class="language-julia"># you can explicit specify the parameters
f = Equalization(nbins = 32)</code></pre><p>For more examples, please check <a href="#ImageContrastAdjustment.HistogramAdjustmentAPI.adjust_histogram"><code>adjust_histogram</code></a>, <a href="#ImageContrastAdjustment.HistogramAdjustmentAPI.adjust_histogram!"><code>adjust_histogram!</code></a> and concrete algorithms.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaImages/ImageContrastAdjustment.jl/blob/5642b3a02e4a24c7f2b528f64870e56f7ab3393e/src/HistogramAdjustmentAPI/histogram_adjustment.jl#L6-L41">source</a></section></article><h3 id="AdaptiveEqualization-1"><a class="docs-heading-anchor" href="#AdaptiveEqualization-1">AdaptiveEqualization</a><a class="docs-heading-anchor-permalink" href="#AdaptiveEqualization-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageContrastAdjustment.AdaptiveEqualization" href="#ImageContrastAdjustment.AdaptiveEqualization"><code>ImageContrastAdjustment.AdaptiveEqualization</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">    AdaptiveEqualization &lt;: AbstractHistogramAdjustmentAlgorithm
    AdaptiveEqualization(; nbins = 256, minval = 0, maxval = 1, rblocks = 8, cblocks = 8, clip = 0.1)

    adjust_histogram([T,] img, f::AdaptiveEqualization)
    adjust_histogram!([out,] img, f::AdaptiveEqualization)</code></pre><p>Performs Contrast Limited Adaptive Histogram Equalisation (CLAHE) on the input image. It differs from ordinary histogram equalization in the respect that the adaptive method computes several histograms, each corresponding to a distinct section of the image, and uses them to redistribute the lightness values of the image. It is therefore suitable for improving the local contrast and enhancing the definitions of edges in each region of an image.</p><p><strong>Details</strong></p><p>Histogram equalisation was initially conceived to  improve the contrast in a single-channel grayscale image. The method transforms the distribution of the intensities in an image so that they are as uniform as possible [1]. The natural justification for uniformity is that the image has better contrast  if the intensity levels of an image span a wide range on the intensity scale. As it turns out, the necessary transformation is a mapping based on the cumulative histogram–-see <a href="#Equalization-1">Equalization</a> for more details.</p><p>A natural extension of histogram equalisation is to apply the contrast enhancement locally rather than globally [2]. Conceptually, one can imagine that the process involves partitioning the image into a grid of rectangular regions and applying histogram equalisation based on the local CDF of each contextual region. However, to smooth the transition of the pixels from one contextual region to another,  the mapping of a pixel is not necessarily done soley based on the local CDF of its contextual region. Rather, the mapping of a pixel may be interpolated based on the CDF of its contextual region, and the CDFs of the immediate neighbouring regions.</p><p>In adaptive histogram equalisation the image <span>$\mathbf{G}$</span> is partitioned into <span>$P \times Q$</span> equisized submatrices,</p><div>\[\mathbf{G} =  \begin{bmatrix}
\mathbf{G}_{11} &amp; \mathbf{G}_{12} &amp; \ldots &amp; \mathbf{G}_{1C} \\
\mathbf{G}_{21} &amp; \mathbf{G}_{22} &amp; \ldots &amp; \mathbf{G}_{2C} \\
\vdots &amp; \vdots &amp; \ldots &amp; \vdots \\
\mathbf{G}_{R1} &amp; \mathbf{G}_{R2} &amp; \ldots &amp; \mathbf{G}_{RC} \\
\end{bmatrix}.\]</div><p>For each submatrix <span>$\mathbf{G}_{rc}$</span>, one computes a concomitant CDF, which we shall denote by <span>$T_{rc}(G_{i,j})$</span>. In the most general case, we will require four CDFs</p><div>\[\begin{aligned}
T_1(v)  &amp; \triangleq  T_{rc}(G_{i,j}) \\
T_2(v)  &amp; \triangleq  T_{(r+1)c}(G_{i,j}) \\
T_3(v)  &amp; \triangleq  T_{(r+1)(c+1)}(G_{i,j}) \\
T_4(v)  &amp; \triangleq  T_{r(c+1)}(G_{i,j}).
\end{aligned}\]</div><p>In order to determine which particular CDFs will be used in the interpolation step, it is useful to (i) introduce the function</p><div>\[\Phi(\mathbf{G}_{rc}) = \left(  \phi_{rc},  \phi&#39;_{rc}\right) \triangleq \left(rP - \frac{P}{2}, cQ - \frac{Q}{2} \right),\]</div><p>(ii) form the sequences  <span>$\left(\phi_{11}, \phi_{21}, \ldots, \phi_{R1} \right)$</span> and <span>$\left(\phi&#39;_{11}, \phi&#39;_{12}, \ldots, \phi&#39;_{1C} \right)$</span>, and (iii) define</p><div>\[\begin{aligned}
t  &amp; \triangleq  \frac{i - \phi_{r1}}{\phi_{(r+1)1} - \phi_{r1} } \\
u  &amp; \triangleq  \frac{j - \phi&#39;_{1c}}{\phi&#39;_{1(c+1)} - \phi&#39;_{1c} }.
\end{aligned}\]</div><p><strong>Case I (Interior)</strong></p><p>For a  pixel <span>$G_{i,j}$</span> in the range</p><div>\[P - \frac{P}{2} \le i \le RP - \frac{P}{2}  \quad \text{and}  \quad  Q - \frac{Q}{2} \le j \le CQ - \frac{Q}{2}.\]</div><p>values of <span>$r$</span> and <span>$c$</span> are implicitly defined by the solution to the inequalities</p><div>\[\phi_{r1} \le i &lt; \phi_{(r+1)1}  \quad \text{and}  \quad  \phi&#39;_{1c} \le j &lt; \phi&#39;_{1(c+1)}.\]</div><p>The <em>bilinearly interpolated</em> transformation that maps an intensity <span>$v$</span> at location <span>$(i,j)$</span> in the image to an intensity <span>$v&#39;$</span> is given by [3]</p><div>\[v&#39; \triangleq \bar{T}(v)  = (1-t) (1-u)T_1(G_{i,j}) + t(1-u)T_2(G_{i,j}) + tuT_3(G_{i,j}) +(1-t)uT_4(G_{i,j}).\]</div><p><strong>Case II (Vertical Border)</strong></p><p>For a  pixel <span>$G_{i,j}$</span> in the range</p><div>\[P - \frac{P}{2} \le i \le RP - \frac{P}{2}  \quad \text{and}  \quad  1 \le j &lt; Q - \frac{Q}{2}  \; \cup \;   CQ - \frac{Q}{2} &lt; j \le CQ,\]</div><p><span>$r$</span> is implicitly defined by the solution to the inequality <span>$\phi_{r1} \le i &lt; \phi_{(r+1)1}$</span>, while</p><div>\[c = \begin{cases}
   1, &amp; \text{if }  \quad  1 \le j &lt; Q - \frac{Q}{2}  \\
   C, &amp; \text{if } \quad   CQ - \frac{Q}{2} &lt; j \le CQ.
\end{cases}\]</div><p>The <em>linearly interpolated</em> transformation that maps an intensity <span>$v$</span> at location <span>$(i,j)$</span> in the image to an intensity <span>$v&#39;$</span> is given by</p><div>\[v&#39; \triangleq \bar{T}(v)  = (1-t)T_1(G_{i,j}) + tT_2(G_{i,j}).\]</div><p><strong>Case III (Horizontal Border)</strong></p><p>For a  pixel <span>$G_{i,j}$</span> in the range</p><div>\[1 \le i &lt; P - \frac{P}{2}  \;\cup \;   RP - \frac{P}{2} &lt; i \le RP    \quad \text{and}  \quad  Q - \frac{Q}{2} \le j \le CQ - \frac{Q}{2},\]</div><p><span>$c$</span> is implicitly defined by the solution to the inequality <span>$\phi&#39;_{1c} \le j &lt; \phi&#39;_{1(c+1)}$</span>, while</p><div>\[r = \begin{cases}
   1, &amp; \text{if }  \quad  1 \le i &lt; P - \frac{P}{2}  \\
   R, &amp; \text{if } \quad   RP - \frac{P}{2} &lt; i \le RP .
\end{cases}\]</div><p>The <em>linearly interpolated</em> transformation that maps an intensity <span>$v$</span> at location <span>$(i,j)$</span> in the image to an intensity <span>$v&#39;$</span> is given by</p><div>\[v&#39; \triangleq \bar{T}(v)  = (1-u)T_1(G_{i,j}) + uT_4(G_{i,j}).\]</div><p><strong>Case IV (Corners)</strong></p><p>For a  pixel <span>$G_{i,j}$</span> in the range</p><div>\[1 \le i &lt; \frac{P}{2}  \;\cup \; RP - \frac{P}{2} &lt; i \le RP   \quad \text{and}  \quad  1 \le j &lt; CQ -  \frac{Q}{2} \; \cup \;   CQ - \frac{Q}{2} &lt; j \le CQ ,\]</div><p>we have</p><div>\[r = \begin{cases}
   1, &amp; \text{if }  \quad  1 \le i &lt; P - \frac{P}{2}  \\
   R, &amp; \text{if } \quad   RP - \frac{P}{2} &lt; i \le RP
\end{cases}
 \quad \text{and}  \quad
c = \begin{cases}
   1, &amp; \text{if }  \quad  1 \le j &lt; Q - \frac{Q}{2}  \\
   C, &amp; \text{if } \quad   CQ - \frac{Q}{2} &lt; j \le CQ.
\end{cases}\]</div><p>The transformation that maps an intensity <span>$v$</span> at location <span>$(i,j)$</span> in the image to an intensity <span>$v&#39;$</span> is given by</p><div>\[v&#39; \triangleq \bar{T}(v)  = T_1(G_{i,j}).\]</div><p><strong>Limiting Contrast</strong></p><p>An unfortunate side-effect of contrast enhancement is that it has a tendency to amplify the level of noise in an image, especially when the magnitude of the contrast enhancement is very high. The magnitude of contrast enhancement is associated with the gradient of <span>$T(\cdot)$</span>, because the  gradient determines the extent to which consecutive input intensities are stretched across the grey-level spectrum. One can diminish the level of noise amplification by limiting the magnitude of the contrast enhancement, that is, by limiting the magnitude of the gradient.</p><p>Since the derivative of <span>$T(\cdot)$</span> is the empirical density <span>$\hat{f}_{G}$</span>, the slope of the mapping function at any input intensity is proportional to the height of the histogram  <span>$\hat{f}_{G}$</span> at that intensity.  Therefore, limiting the slope of the local mapping function is equivalent to clipping the height of the histogram. A detailed description of the  implementation  details of the clipping process can be found in [2].</p><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>img</code></strong></p><p>The function can handle a variety of input types. The returned image depends on the input type.</p><p>For coloured images, the input is converted to <a href="https://en.wikipedia.org/wiki/YIQ">YIQ</a> type and the Y channel is equalised. This is the combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choices for <code>nbins</code> in <code>AdaptiveEqualization</code></strong></p><p>You can specify the total number of bins in the histogram of each local region.</p><p><strong>Choices for <code>rblocks</code> and <code>cblocks</code> in <code>AdaptiveEqualization</code></strong></p><p>The <code>rblocks</code> and <code>cblocks</code> specify the number of blocks to divide the input image into in each direction. By default both values are set to eight.</p><p><strong>Choices for <code>clip</code> in <code>AdaptiveEqualization</code></strong></p><p>The <code>clip</code> parameter must be a value between 0 and 1. It defines an implicit threshold at which a histogram is clipped. Counts that exceed the threshold are redistributed as equally as possible so that no bin exceeds the threshold limit. A value of zero means no clipping, whereas a value of one sets the threshold at the smallest feasible bin limit. A bin limit is feasible if all bin counts can be redistributed such that no bin count exceeds the limit. In practice, a <code>clip</code> value of zero corresponds to maximal contrast enhancement, whereas a <code>clip</code> value of one corredponds to minimal contrast enhancement. The default value is <code>0.1</code>.</p><p><strong>Choices for <code>minval</code> and <code>maxval</code> in <code>AdaptiveEqualization</code></strong></p><p>If <code>minval</code> and <code>maxval</code> are specified then intensities are equalized to the range [<code>minval</code>, <code>maxval</code>]. The default values are 0 and 1.</p><p><strong>Example</strong></p><pre><code class="language-julia">
using TestImages, FileIO, ImageView

img =  testimage(&quot;mandril_gray&quot;)
imgeq = adjust_histogram(img, AdativeEqualization(nbins = 256, rblocks = 4, cblocks = 4, clip = 0.2))

imshow(img)
imshow(imgeq)</code></pre><p><strong>References</strong></p><ol><li>R. C. Gonzalez and R. E. Woods. <em>Digital Image Processing (3rd Edition)</em>.  Upper Saddle River, NJ, USA: Prentice-Hall,  2006.</li><li>S. M. Pizer, E. P. Amburn, J. D. Austin, R. Cromartie, A. Geselowitz, T. Greer, B. ter Haar Romeny, J. B. Zimmerman and K. Zuiderveld “Adaptive histogram equalization and its variations,” <em>Computer Vision, Graphics, and Image Processing</em>, vol. 38, no. 1, p. 99, Apr. 1987. <a href="https://doi.org/10.1016/s0734-189x(87)80156-1">10.1016/S0734-189X(87)80186-X</a></li><li>W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery.  <em>Numerical Recipes: The Art of Scientific Computing (3rd Edition)</em>. New York, NY, USA: Cambridge University Press, 2007.</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/80516ca20297a67b996caa08c38786332379b6a5/base/#L0-L240">source</a></section></article><h3 id="ContrastStretching-1"><a class="docs-heading-anchor" href="#ContrastStretching-1">ContrastStretching</a><a class="docs-heading-anchor-permalink" href="#ContrastStretching-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageContrastAdjustment.ContrastStretching" href="#ImageContrastAdjustment.ContrastStretching"><code>ImageContrastAdjustment.ContrastStretching</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">    ContrastStretching &lt;: AbstractHistogramAdjustmentAlgorithm
    ContrastStretching(; t = 0.5,  slope = 1.0)

    adjust_histogram([T,] img, f::ContrastStretching)
    adjust_histogram!([out,] img, f::ContrastStretching)</code></pre><p>Returns an image where intensities below <code>t</code> are compressed into a narrower range of dark intensities, and values above <code>t</code> are compressed into a narrower band of light intensities.</p><p><strong>Details</strong></p><p>Contrast stretching is a transformation that  enhances or reduces (for <code>slope</code> &gt; 1 or &lt; 1, respectively) the contrast near saturation (0 and 1). It is given by the relation</p><div>\[f(x) = \frac{1}{1 + \left(\frac{t}{x} \right)^s}, \; s \in \mathbb{R},\]</div><p>where <span>$s$</span> represents the <code>slope</code> argument.</p><p><strong>Options</strong></p><p>Various options for the parameters of the <code>adjust_histogram</code> and <code>ContrastStretching</code> type are described in more detail below.</p><p><strong>Choices for <code>img</code></strong></p><p>The function can handle a variety of input types. The returned image depends on the input type.</p><p>For colored images, the input is converted to the <a href="https://en.wikipedia.org/wiki/YIQ">YIQ</a>  type and the intensities of the Y channel are stretched to the specified range. The modified Y channel is then combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choice for <code>t</code></strong></p><p>The value of <code>t</code> needs to be in the unit interval. If left unspecified a default value of 0.5 is utilized.</p><p><strong>Choice for <code>slope</code></strong></p><p>The value of <code>slope</code> can be any real number. If left unspecified a default value of 1.0 is utilized.</p><p><strong>Example</strong></p><pre><code class="language-julia">using ImageContrastAdjustment, ImageView, TestImages

img = testimage(&quot;mandril_gray&quot;)
ret = adjust_histogram(img, ContrastStretching(t = 0.6, slope = 3))
</code></pre><p><strong>References</strong></p><ol><li>Gonzalez, R. C., Woods, R. E., &amp; Eddins, S. L. (2004). <em>Digital image processing using MATLAB</em> (Vol. 624). Upper Saddle River, New Jersey: Pearson-Prentice-Hall.</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/80516ca20297a67b996caa08c38786332379b6a5/base/#L0-L62">source</a></section></article><h3 id="Equalization-1"><a class="docs-heading-anchor" href="#Equalization-1">Equalization</a><a class="docs-heading-anchor-permalink" href="#Equalization-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageContrastAdjustment.Equalization" href="#ImageContrastAdjustment.Equalization"><code>ImageContrastAdjustment.Equalization</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">    Equalization &lt;: AbstractHistogramAdjustmentAlgorithm
    Equalization(; nbins = 256, minval = 0, maxval = 1)

    adjust_histogram([T,] img, f::Equalization)
    adjust_histogram!([out,] img, f::Equalization)</code></pre><p>Returns a histogram equalized image with a granularity of <code>nbins</code> number of bins.</p><p><strong>Details</strong></p><p>Histogram equalization was initially conceived to  improve the contrast in a single-channel grayscale image. The method transforms the distribution of the intensities in an image so that they are as uniform as possible [1]. The natural justification for uniformity is that the image has better contrast  if the intensity levels of an image span a wide range on the intensity scale. As it turns out, the necessary transformation is a mapping based on the cumulative histogram.</p><p>One can consider an <span>$L$</span>-bit single-channel <span>$I \times J$</span> image with gray values in the set <span>$\{0,1,\ldots,L-1 \}$</span>, as a collection of independent and identically distributed random variables. Specifically, let the sample space <span>$\Omega$</span> be the set of all <span>$IJ$</span>-tuples <span>$\omega =(\omega_{11},\omega_{12},\ldots,\omega_{1J},\omega_{21},\omega_{22},\ldots,\omega_{2J},\omega_{I1},\omega_{I2},\ldots,\omega_{IJ})$</span>, where each <span>$\omega_{ij} \in \{0,1,\ldots, L-1 \}$</span>. Furthermore, impose a probability measure on <span>$\Omega$</span> such that the functions <span>$\Omega \ni \omega \to \omega_{ij} \in \{0,1,\ldots,L-1\}$</span> are independent and identically distributed.</p><p>One can then regard an image as a matrix of random variables <span>$\mathbf{G} = [G_{i,j}(\omega)]$</span>, where each function <span>$G_{i,j}: \Omega \to \mathbb{R}$</span> is defined by</p><div>\[G_{i,j}(\omega) = \frac{\omega_{ij}}{L-1},\]</div><p>and each <span>$G_{i,j}$</span> is distributed according to some unknown density <span>$f_{G}$</span>. While <span>$f_{G}$</span> is unknown, one can approximate it with a normalized histogram of gray levels,</p><div>\[\hat{f}_{G}(v)= \frac{n_v}{IJ},\]</div><p>where</p><div>\[n_v = \left | \left\{(i,j)\, |\,  G_{i,j}(\omega)  = v \right \} \right |\]</div><p>represents the number of times a gray level with intensity <span>$v$</span> occurs in <span>$\mathbf{G}$</span>. To transform the distribution of the intensities so that they are as uniform as possible one needs to find a mapping <span>$T(\cdot)$</span> such that <span>$T(G_{i,j}) \thicksim U$</span>. The required mapping turns out to be the cumulative distribution function (CDF) of the empirical density <span>$\hat{f}_{G}$</span>,</p><div>\[ T(G_{i,j}) = \int_0^{G_{i,j}}\hat{f}_{G}(w)\mathrm{d} w.\]</div><p><strong>Options</strong></p><p>Various options for the parameters of the <code>adjust_histogram</code> function and <code>Equalization</code> type are described in more detail below.</p><p><strong>Choices for <code>img</code></strong></p><p>The <code>adjust_histogram</code> function can handle a variety of input types.  By default type of the returned image matches the input type.</p><p>For colored images, the input is converted to <a href="https://en.wikipedia.org/wiki/YIQ">YIQ</a> type and the Y channel is equalized. This is the combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choices for <code>nbins</code> in <code>Equalization</code></strong></p><p>You can specify the total number of bins in the histogram.</p><p><strong>Choices for <code>minval</code> and <code>maxval</code> in <code>Equalization</code></strong></p><p>If <code>minval</code> and <code>maxval</code> are specified then intensities are equalized to the range [<code>minval</code>, <code>maxval</code>]. The default values are 0 and 1.</p><p><strong>Example</strong></p><pre><code class="language-julia">
using TestImages, FileIO, ImageView

img =  testimage(&quot;mandril_gray&quot;)
imgeq = adjust_histogram(img, Equalization(nbins = 256, minval = 0, maxval = 1))

imshow(img)
imshow(imgeq)</code></pre><p><strong>References</strong></p><ol><li>R. C. Gonzalez and R. E. Woods. <em>Digital Image Processing (3rd Edition)</em>.  Upper Saddle River, NJ, USA: Prentice-Hall,  2006.</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/80516ca20297a67b996caa08c38786332379b6a5/base/#L0-L97">source</a></section></article><h3 id="LinearStretching-1"><a class="docs-heading-anchor" href="#LinearStretching-1">LinearStretching</a><a class="docs-heading-anchor-permalink" href="#LinearStretching-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageContrastAdjustment.LinearStretching" href="#ImageContrastAdjustment.LinearStretching"><code>ImageContrastAdjustment.LinearStretching</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">    LinearStretching &lt;: AbstractHistogramAdjustmentAlgorithm
    LinearStretching(; [src_minval], [src_maxval],
                       dst_minval=0, dst_maxval=1,
                       no_clamp=false)

    LinearStretching((src_minval, src_maxval) =&gt; (dst_minval, dst_maxval))
    LinearStretching((src_minval, src_maxval) =&gt; nothing)
    LinearStretching(nothing =&gt; (dst_minval, dst_maxval))

    adjust_histogram([T,] img, f::LinearStretching)
    adjust_histogram!([out,] img, f::LinearStretching)</code></pre><p>Returns an image where the range of the intensities spans the interval [<code>dst_minval</code>, <code>dst_maxval</code>].</p><p><strong>Details</strong></p><p>Linear stretching (also called <em>normalization</em>) is a contrast enhancing transformation that is used to modify the dynamic range of the image. In particular, suppose that the input image has gray values in the range [A,B] and one wishes to change the dynamic range to [a,b] using a linear mapping, then the necessary transformation is given by the relation</p><div>\[f(x) = (x-A) \frac{b-a}{B-A} + a.\]</div><p><strong>Options</strong></p><p>Various options for the parameters of the <code>adjust_histogram</code> and <code>LinearStretching</code> type  are described in more detail below.</p><p><strong>Choices for <code>img</code></strong></p><p>The function can handle a variety of input types. The returned image depends on the input type.</p><p>For colored images, the input is converted to the <a href="https://en.wikipedia.org/wiki/YIQ">YIQ</a>  type and the intensities of the Y channel are stretched to the specified range. The modified Y channel is then combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choices for <code>dst_minval</code> and <code>dst_maxval</code></strong></p><p>If destination value range <code>dst_minval</code> and <code>dst_maxval</code> are specified then intensities are mapped to the range [<code>dst_minval</code>, <code>dst_maxval</code>]. The default values are 0 and 1.</p><p><strong>Choices for <code>src_minval</code> and <code>src_maxval</code></strong></p><p>The source value range <code>src_minval</code> and <code>src_maxval</code> specifies the intensity range of input image. By default, the values are <code>extrema(img)</code> (finite). If custom values are provided, the output intensity value will be clamped to range <code>[dst_minval, dst_maxval]</code> if it exceeds that.</p><p><strong><code>no_clamp</code></strong></p><p>Setting <code>no_clamp=true</code> to disable the automatic clamp even if the output intensity value exceeds the range <code>[dst_minval, dst_maxval]</code>. Note that a clamp is still applied for types that has limited value range, for example, if the input eltype is <code>N0f8</code>, then the output will be clamped to <code>[0.0N0f8, 1.0N0f8]</code> even if <code>no_clamp==true</code>.</p><p><strong>Example</strong></p><pre><code class="language-julia">using ImageContrastAdjustment, TestImages

img = testimage(&quot;mandril_gray&quot;)
# Stretches the contrast in `img` so that it spans the unit interval.
imgo = adjust_histogram(img, LinearStretching(dst_minval = 0, dst_maxval = 1))</code></pre><p>For convenience, Constructing a <code>LinearStretching</code> object using <code>Pair</code> is also supported</p><pre><code class="language-julia"># these two constructors are equivalent
LinearStretching(src_minval=0.1, src_maxval=0.9, dst_minval=0.05, dst_maxval=0.95)
LinearStretching((0.1, 0.9) =&gt; (0.05, 0.95))

# replace the part with `nothing` to use default values, e.g.,
# specify only destination value range
LinearStretching(nothing =&gt; (0.05, 0.95))
# specify only source value range and use default destination value range, i.e., (0, 1)
LinearStretching((0.1, 0.9) =&gt; nothing)</code></pre><p><strong>References</strong></p><ol><li>W. Burger and M. J. Burge. <em>Digital Image Processing</em>. Texts in Computer Science, 2016. <a href="https://doi.org/10.1007/978-1-4471-6684-9">doi:10.1007/978-1-4471-6684-9</a></li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/80516ca20297a67b996caa08c38786332379b6a5/base/#L0-L91">source</a></section></article><h3 id="Matching-1"><a class="docs-heading-anchor" href="#Matching-1">Matching</a><a class="docs-heading-anchor-permalink" href="#Matching-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageContrastAdjustment.Matching" href="#ImageContrastAdjustment.Matching"><code>ImageContrastAdjustment.Matching</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">    Matching &lt;: AbstractHistogramAdjustmentAlgorithm
    Matching(targetimg; nbins = 256, edges = nothing)

    adjust_histogram([T,] img, f::Matching)
    adjust_histogram!([out,] img, f::Matching)</code></pre><p>Returns a histogram matched image with a granularity of <code>nbins</code> number of bins. The first argument <code>img</code> is the image to be matched, whereas the argument <code>targetimg</code> in <code>Matching()</code> is the image having the desired histogram to be matched to.</p><p><strong>Details</strong></p><p>The purpose of histogram matching is to transform the intensities in a source image so that the intensities distribute according to the histogram of a specified target image. If one interprets histograms as piecewise-constant models of probability density functions (see <a href="#ImageContrastAdjustment.build_histogram"><code>build_histogram</code></a>), then the histogram matching task can be modelled as the problem of transforming one probability distribution into another [1]. It turns out that the solution to this transformation problem involves the cumulative and inverse cumulative distribution functions of the source and target probability density functions.</p><p>In particular, let the random variables <span>$x \thicksim p_{x}$</span> and <span>$z \thicksim p_{z}$</span>  represent an intensity in the source and target image respectively, and let</p><div>\[ S(x) = \int_0^{x}p_{x}(w)\mathrm{d} w \quad \text{and} \quad
 T(z) = \int_0^{z}p_{z}(w)\mathrm{d} w\]</div><p>represent their concomitant cumulative distribution functions. Then the sought-after mapping <span>$Q(\cdot)$</span> such that <span>$Q(x) \thicksim p_{z}$</span> is given by</p><div>\[Q(x) =  T^{-1}\left( S(x) \right),\]</div><p>where <span>$T^{-1}(y) = \operatorname{min} \{ x \in \mathbb{R} : y \leq T(x) \}$</span> is the inverse cumulative distribution function of <span>$T(x)$</span>.</p><p>The mapping suggests that one can conceptualize histogram matching as performing histogram equalization on the source and target image and relating the two equalized histograms. Refer to <a href="#ImageContrastAdjustment.HistogramAdjustmentAPI.adjust_histogram"><code>adjust_histogram</code></a> for more details on histogram equalization.</p><p><strong>Options</strong></p><p>Various options for the parameters of the <code>adjust_histogram</code> function and <code>Matching</code> type are described in more detail below.</p><p><strong>Choices for <code>img</code> and <code>targetimg</code></strong></p><p>The <code>adjust_histogram(img, Matching())</code> function can handle a variety of input types. The type of the returned image matches the input type.</p><p>For colored images, the inputs are converted to <a href="https://en.wikipedia.org/wiki/YIQ">YIQ</a>  type and the distributions of the Y channels are matched. The modified Y channel is then combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choices for <code>nbins</code></strong></p><p>You can specify the total number of bins in the histogram. If you do not specify the number of bins then a default value of 256 bins is utilized.</p><p><strong>Choices for <code>edges</code></strong></p><p>If you do not designate the number of bins, then you have the option to directly stipulate how the intervals will be divided by specifying a <code>AbstractRange</code> type.</p><p><strong>Example</strong></p><pre><code class="language-julia">using Images, TestImages, ImageView

img_source = testimage(&quot;mandril_gray&quot;)
img_target = adjust_histogram(img_source, GammaCorrection(gamma = 0.5))
img_transformed = adjust_histogram(img_source, Matching(targetimg = img_target))
#=
    A visual inspection confirms that img_transformed resembles img_target
    much more closely than img_source.
=#
imshow(img_source)
imshow(img_target)
imshow(img_transformed)</code></pre><p><strong>References</strong></p><ol><li>W. Burger and M. J. Burge. <em>Digital Image Processing</em>. Texts in Computer Science, 2016. <a href="https://doi.org/10.1007/978-1-4471-6684-9">doi:10.1007/978-1-4471-6684-9</a></li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/80516ca20297a67b996caa08c38786332379b6a5/base/#L0-L97">source</a></section></article><h3 id="MidwayEqualization-1"><a class="docs-heading-anchor" href="#MidwayEqualization-1">MidwayEqualization</a><a class="docs-heading-anchor-permalink" href="#MidwayEqualization-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageContrastAdjustment.MidwayEqualization" href="#ImageContrastAdjustment.MidwayEqualization"><code>ImageContrastAdjustment.MidwayEqualization</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">    MidwayEqualization &lt;: AbstractHistogramAdjustmentAlgorithm
    MidwayEqualization(; nbins = 256, minval = 0, maxval = 1)

    adjust_histogram([T,] img_sequence, f::MidwayEqualization(nbins = 256, edges = nothing))
    adjust_histogram!([out_sequence,] img_sequence, f::MidwayEqualization(nbins = 256, edges = nothing))</code></pre><p>Gives a pair of images the same histogram whilst maintaining as much as possible their previous grey level dynamics.</p><p><strong>Details</strong></p><p>The purpose of midway histogram equalization is to transform the intensities in a pair of images so that the intensities distribute according to a common &quot;midway&quot; distribution. The histogram representing the common distribution is chosen so that the original  gray level dynamics of the images are preserved as much as possible. If one interprets histograms as piecewise-constant models of probability density functions (see <a href="#ImageContrastAdjustment.build_histogram"><code>build_histogram</code></a>), then the midway histogram equalization task can be modeled as the problem of transforming one probability distribution into another (see <a href="#ImageContrastAdjustment.HistogramAdjustmentAPI.adjust_histogram"><code>adjust_histogram</code></a>). It turns out that the solution to this transformation problem involves the cumulative and inverse cumulative distribution functions of the source and &quot;midway&quot; probability density functions. In particular, let the random variables <span>$X_i \thicksim p_{x_i} \; (i = 1,2)$</span>, and <span>$Z \thicksim p_{z}$</span>  represent an intensity in the first, second and &quot;midway&quot; image respectively, and let</p><div>\[ S_{X_i}(x) = \int_0^{x}p_{x_i}(w)\mathrm{d} w \; \quad \text{and} \quad
 T_{Z}(x) = \frac{2}{\frac{1}{S_{X_1}(x)} + \frac{1}{S_{X_2}(x)}}\]</div><p>represent the cumulative distribution functions of the two input images, and their <em>harmonic mean</em>, respectively. Then the sought-after mapping <span>$Q_{X_i}(\cdot)$</span> <span>$(i = 1,2)$</span> such that <span>$Q_{X_i}(x) \thicksim p_{z}$</span> is given by</p><div>\[Q_{X_i}(x) =  T_{Z}^{-1}\left( S_{X_i}(x) \right),\]</div><p>where <span>$T_{Z}^{-1}(y) = \operatorname{min} \{ x \in \mathbb{R} : y \leq T_{Z}(x) \}$</span> is the inverse cumulative distribution function of <span>$T_{Z}(x)$</span>.</p><p><strong>Options</strong></p><p>Various options for the parameters of the <code>adjust_histogram</code> function and <code>MidwayEqualization</code> types are described in more detail below.</p><p><strong>Choices for <code>img_sequence</code></strong></p><p>The function <code>adjust_histogram</code> expects a length-2 <code>Vector</code> of images (the pair of images) and returns a length-2 <code>Vector</code> of modified images.  The  function can handle a variety of input types. The type of the returned image matches the input type.</p><p>For colored images, the inputs are converted to <a href="https://en.wikipedia.org/wiki/YIQ">YIQ</a>  type and the distributions of the Y channels are transformed according to a &quot;midway&quot; distribution. The modified Y channel is then combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choices for <code>nbins</code></strong></p><p>You can specify the total number of bins in the histogram. If you do not specify the number of bins then a default value of 256 bins is utilized.</p><p><strong>Choices for <code>edges</code></strong></p><p>If you do not designate the number of bins, then you have the option to directly stipulate how the intervals will be divided by specifying a <code>AbstractRange</code> type.</p><p><strong>Example</strong></p><pre><code class="language-julia">using Images, TestImages, ImageView, ImageContrastAdjustment

img = testimage(&quot;mandril_gray&quot;)

# The same image but with different intensitiy distributions
img1 = adjust_histogram(img, GammaCorrection(gamma = 2))
img2 = adjust_histogram(img, GammaCorrection(gamma = 1.2))

# Midway histogram equalization will transform these two images so that their
# intensity distributions are almost identical.
img_sequence = adjust_histogram([img1, img2], MidwayEqualization(nbins = 256))
img1o = first(img_sequence)
img2o = last(img_sequence)</code></pre><p><strong>References</strong></p><ol><li>T. Guillemot and J. Delon, “<em>Implementation of the Midway Image Equalization</em>,” Image Processing On Line, vol. 5, pp. 114–129, Jun. 2016. <a href="https://doi.org/10.5201/ipol.2016.140">doi:10.5201/ipol.2016.140</a></li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/80516ca20297a67b996caa08c38786332379b6a5/base/#L0-L96">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« ImageContrastAdjustment.jl Documentation</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 15 April 2020 11:40">Wednesday 15 April 2020</span>. Using Julia version 1.1.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
